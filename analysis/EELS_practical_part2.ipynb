{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0d829d",
   "metadata": {},
   "source": [
    "# How to read this document\n",
    "\n",
    "This document is designed to showcase the different basic functionality of Hyperspy for the analysis of EELS data. This notebook is split in five main parts:\n",
    "\n",
    "#### I. Introduction to Hyperspy\n",
    "\n",
    "#### II. Data visualisation\n",
    "\n",
    "#### III. Core-loss analysis\n",
    "\n",
    "#### IV. Los-loss analysis\n",
    "\n",
    "#### V. Machine learning\n",
    "\n",
    "**The jupyter notebook extensions are installed. Thus, you can navigate between sections using the left panel**\n",
    "\n",
    "Not everything is intended to be read the from the first time. Optional comments along the document are marked by emojis: \n",
    "- ‚≠ê This is a tip, describing more in depth the inner workings of hyperspy.\n",
    "- üè† It's an optional comment. Something that you may not use here but that you can use back to your lab.\n",
    "\n",
    "## Using Jupyter\n",
    "\n",
    "- Autocompletion: When you are typing code and ask for a function of an object (e.g., `data.`), just after typing the dot you can press tab to see the possible options. You can continue typing to reduce the number of possibilities.\n",
    "\n",
    "- Contextual help: I recommend that you have a quick acces to the documentation opened in a tab. Go to the top menu bar and click on \"Help --> Show Contextual Help\". Positioning you pointer next to a code part will show you its associated documentation.\n",
    "\n",
    "- Inline help: If the above does not work you can also type a `?` at the end of a function (e.g., `data.function?`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9fbb6",
   "metadata": {},
   "source": [
    "# I. Introduction to Hyperspy\n",
    "\n",
    "![image](images/hyperspy_logo.png)\n",
    "\n",
    "Hyperspy is a tool for the visualisation and manipulation of high-dimensional data. The main features of Hyperspy are the following:\n",
    "- The Signal1D and Signal2D objects\n",
    "- Model fitting\n",
    "- Machine learning\n",
    "\n",
    "Over the years, the hyperspy community has built a rich environment of domain-specific packages for hyperspy-based data analysis. In this notebook, we will use exspy:\n",
    "\n",
    "![image](images/exspy_logo.png)\n",
    "\n",
    "A large part of this practical is inspired from the hyperspy documentation : http://hyperspy.org/hyperspy-doc/current/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13671f17",
   "metadata": {},
   "source": [
    "## Import Hyperspy\n",
    "\n",
    "‚≠ê We choose first a graphical backend that manage interactivity (```%matplotlib qt```).\n",
    "\n",
    "‚≠ê We can cancel the appearance of warnings for better readability (```warnings.filterwarnings('ignore')```).\n",
    "\n",
    "In python the libraries have to be imported to use their functions. For clarity, hyperspy will be imported with the name ```hs```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399c797",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Hyperspy is able to load and manage data from many different open-source and proprietary formats, such as: \n",
    "- dm3, dm4\n",
    "- emd, bcf\n",
    "- tiff, jpg, etc...\n",
    "\n",
    "For an exhaustive list : http://hyperspy.org/hyperspy-doc/current/user_guide/io.html#supported-formats\n",
    "\n",
    "‚≠ê Without arguments ```hs.load()```  makes a file explorer window pop up. You can also load a list of files.\n",
    "\n",
    "üè† Depending on the file format it loads either as a directly usable dataset (e.g. dm3, dm4) or as a list of datasets (e.g. bcf, emd). You can then work on the elements of the loaded list.\n",
    "\n",
    "The data below were kindly provided by: **Maya Marinova**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_loss = hs.load(...)\n",
    "core_loss = ...\n",
    "adf = ...\n",
    "adf_survey = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066228c9",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "The loaded data also contain metadata. We will see that some of these metadata are used for specific functions (e.g. beam energy), such as modelling. In this tutorial all the relevant metatadata is already filled in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d66dd0",
   "metadata": {},
   "source": [
    "### Orginal metadata\n",
    "\n",
    "Sometimes the import fails to retrieve important metadata. They can be inspected using the `original_metadata` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original metadata\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3ec2e",
   "metadata": {},
   "source": [
    "### Modify metadata\n",
    "\n",
    "You can modifiy any field of the metadata to suit your needs in two ways:\n",
    "- Using helper functions such as `set_microscope_parameters`\n",
    "- Directly modifying the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80045c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microscope parameters\n",
    "core_loss...\n",
    "# elements\n",
    "core_loss...\n",
    "# metadata entry\n",
    "core_loss...\n",
    "# print\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682d556",
   "metadata": {},
   "source": [
    "## Signals\n",
    "\n",
    "### navigation and signal dimensions\n",
    "\n",
    "The key feature of hyperspy are the Signal objects. They are based on the concept of separating array dimensions between navigation and signal. The navigation axes are considered as sampling of the collected signal. **Hence, not all axes are treated equally, which enables an easier handling of high dimensional data.** Most Hyperspy functions operate of the signal axes and iterate over the navigation axes. For instance, when calling `signal.mean()`, it will, by default, return the mean of the signal over the navigation dimension. \n",
    "\n",
    "In STEM-EELS spectrum-imaging, EELS spectra contain the signal of interest that are sampled over an area. In this case, X and Y are the navigation axes and E is the signal axis. Calling `signal.mean()` will thus conviniently return the mean EELS spectrum.\n",
    "\n",
    "The notation is as follows: `(navigation axes| signal axes>`.\n",
    "\n",
    "Signals axes are either 1D or 2D as it is usually a convinient representation of signals. \n",
    "\n",
    "‚≠ê You can change the axes from signal to navigation using the transpose operation : `signal.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd021d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9171bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a980b",
   "metadata": {},
   "source": [
    "### axes_manager\n",
    "\n",
    "The different axes, their calibration and properties are stored in the `axes_manager` attribute. A Graphical User Interface (gui), is provided by Hyperspy  \n",
    "\n",
    "üè† You can bypass the gui using `signal.axes_manager.navigation_axes[...]` or `signal.axes_manager.signal_axes[...]`. You can set their properties as `signal.axes_manager.navigation_axes.set(name=(\"X\", \"Y\"), offset=10, units=\"nm\")`. Once the axes have a name you can also acces the axes directly: `signal.axes_manager['X']`.\n",
    "\n",
    "‚≠ê Hyperspy can also handle non-linear axes. See DataAxis or FunctionalDataAxis in Hyperspy documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b849a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# axes_manager\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gui\n",
    "core_loss.axes_manager..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053d553",
   "metadata": {},
   "source": [
    "### Slicing data\n",
    "\n",
    "The signals also provide a convinient way to slice data according to your needs. You can slice either along the navigation axes using `signal.inav` or along the signals axes using `signal.isig`. The syntax is then the following: \n",
    "```\n",
    "signal.inav[start:stop:step]\n",
    "```\n",
    "\n",
    "Note that `start`, `stop` and `step` can be floats or string, expressed in calibrated units. By default, `start` = 0, `stop` = -1 and `step` = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Slice using array indices : \",core_loss...)\n",
    "print(\"Slice using calibrated values : \",core_loss...)\n",
    "print(\"Slice one over two values : \",core_loss...)\n",
    "print(\"Slice using eVs : \",core_loss...)\n",
    "print(\"Slice using meVs : \",core_loss...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9929877",
   "metadata": {},
   "source": [
    "### Signal types\n",
    "\n",
    "The signals are usually from of a child-type of `Signal1D` or `Signal2D`, that originate from domain-specific python packages directly linked to Hyperspy. This is illustrated just below:\n",
    "\n",
    "![image](images/HyperSpySignalOverview.png)\n",
    "\n",
    "Each child-type implements domain-specific functions for data analysis. For instance, in this notebook we will take advantage of functions specific to the analysis of EELS spectra using the `EELSSpectrum` object.\n",
    "\n",
    "Here is a link to the list of Hyperspy extensions:\n",
    "[List of Hyperspy extensions](https://github.com/hyperspy/hyperspy-extensions-list)\n",
    "\n",
    "‚≠ê‚≠ê You can code your own extensions, see the online tutorial: [How to write an extension](https://hyperspy.org/hyperspy-doc/current/dev_guide/writing_extensions.html)\n",
    "\n",
    "#### Printing the installed child-signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89338460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print known signal types\n",
    "hs..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196d0fb",
   "metadata": {},
   "source": [
    "# II. Data visualisation\n",
    "\n",
    "Hyperspy also provides gui elements for data visualisation. Executing the cell below enables you to browse the data in similar way as with DigitalMicrograph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14093a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ROI object. Without arguments it will use default coordinates, that are usually working well.\n",
    "roi = hs.roi.RectangularROI()\n",
    "\n",
    "# Plotting the different datasets\n",
    "low_loss.plot()\n",
    "core_loss.plot()\n",
    "adf.plot()\n",
    "\n",
    "# Linking the ROI with the datasets\n",
    "ll_select = roi.interactive(low_loss)\n",
    "cl_select = roi.interactive(core_loss)\n",
    "roi.interactive(adf)\n",
    "\n",
    "# Summing over the spectrum images\n",
    "ll_spectrum = hs.interactive(ll_select.mean)\n",
    "cl_spectrum = hs.interactive(cl_select.mean)\n",
    "\n",
    "# Plotting the spectra\n",
    "ll_spectrum.plot()\n",
    "cl_spectrum.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52a789",
   "metadata": {},
   "source": [
    "# III. Core-loss analysis\n",
    "\n",
    "üè† In this practical we will mostly use the gui elements of Hyperspy, which in general, work the following way:\n",
    "- If it is an attribute such as `signal.axes_manager` you can call the `signal.axes_manager.gui()` function.\n",
    "- If it is a function such as `signal.axes_manager.remove_background()` you can call it without arguments, and it will activate the gui. You can still call the function with arguments (Check the contextual help to know which arguments to use).\n",
    "Everything shown here also work without the gui elements.\n",
    "\n",
    "üè† Most gui elements of Hyperspy provide a corresponding 'Help' section. \n",
    "\n",
    "## Pre-processing\n",
    "\n",
    "### (Optional) Calibration\n",
    "\n",
    "The `signal.calibrate()` function works similarly as in Digital Micrograph. You can select a range on a picked spectrum with identifiable features and apply the calibration. This overwrites the `axes_manager` values and works on the signal axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_loss.calibrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6806f",
   "metadata": {},
   "source": [
    "### X-ray removal\n",
    "\n",
    "Hyperspy also provides a convinient way to remove cosmic X-rays from the spectrum image: the function `spikes_removal_tool`. Note that, this procedure overwrites the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7252b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_removal\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cfea9",
   "metadata": {},
   "source": [
    "### Align energy\n",
    "\n",
    "We can first plot the estimated zero-loss peak energy position and check if the estimation seems correct. The `estimate_zero_loss_peak_centre` function returns a signal that we need then to plot. This step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate zero loss + plot\n",
    "low_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3cb3b",
   "metadata": {},
   "source": [
    "If the estimation seems correct, we can apply the energy shift correction using the `align_zero_loss_peak` function. The energy shift is also applied to a list of other signals with the same dimensions using the `also_align` keyword argument.\n",
    "\n",
    "üè† If you have a peak with higher intensity than the zero-loss it is best to precise the energy range over which to align in energy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align zero loss (also_align: list)\n",
    "low_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae0274",
   "metadata": {},
   "source": [
    "### Remove plural scattering\n",
    "\n",
    "The electrons can undergo several inelastic scattering events during their travel inside of the sample. However we want to access the single scattering distribution which directly correspond to a physically meaningfull spectrum (as direct measure of transitions probabilty). The single scattering distribution is given by : \n",
    "\n",
    "$$ S_{1}(E) = I_{0} t \\theta(E) * \\sigma(E) $$\n",
    "\n",
    "Where $I_{0}$ is the incoming beam intensity, $t$ is the thickness of the sample, $\\theta(E)$ is the zero loss peak and $\\sigma(E)$ is inelastic scattering spectrum. The zero loss peak is already convolved to the spectrum. Thus, even in the case of single scattering, the deconvolution can improve the energy resolution. When the sample is too thick, the spectrum is dominated by the multiple scattering distribution and $\\sigma(E)$ can not be straightforwardly obtained.\n",
    "\n",
    "For example, the double scattering distribution is given by : \n",
    "\n",
    "$$ S_{2}(E) = I_{0} \\frac{t^{2}}{2} \\theta(E) * \\sigma(E) * \\sigma(E) $$\n",
    "\n",
    "In that case, it is important to perform the deconvolution with the full low loss spectrum. \n",
    "\n",
    "#### Thickness estimation\n",
    "\n",
    "We can first estimate the thickness of the sample with the `estimate_thickness` function that computes the relative thickness over a low loss EELS dataset. Since it outputs a Signal2D, we use the `plot` function to inspect the results.\n",
    "\n",
    "The first argument is the energy threshold below which the signal is integrated to calculate the thickness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate thickness + plot\n",
    "low_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814439f",
   "metadata": {},
   "source": [
    "#### Deconvolution\n",
    "\n",
    "The Richardson-Lucy algorithm can be used to deconvolve the effect of plural scattering from the core-loss. It is usually the prefered deconvolution method in EELS. The low-loss is used through the `psf` keyword argument. The number of iterations (`iterations =`) is a key parameter here, depending on your dataset you should increase it or decrease it. If you use too many iterations, you will see ripples artefacts appear.\n",
    "\n",
    "üè† See the \"gloter2003_eels_deconvolution.pdf\" for more information on deconvolution in EELS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# richardson_lucy \n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84dad2",
   "metadata": {},
   "source": [
    "## Edge identification and extraction\n",
    "\n",
    "Hyperspy has a dedicated tool for edge identification that gives you all the possible edge at the selected energy range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24784d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges at energy\n",
    "core_loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d0c8b",
   "metadata": {},
   "source": [
    "### Extracting edges\n",
    "\n",
    "The EELSSpectrum object has an implementation of power law background removal for edge extraction. The instruction on how to use the function are described during execution. Here we apply the background removal on a single spectrum (extracted above).\n",
    "\n",
    "For EELS, the Power Law background is the most adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d84d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_background\n",
    "cl_spectrum..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925f20e",
   "metadata": {},
   "source": [
    "## Elemental mapping\n",
    "\n",
    "While there is a helper function in Energy-Dispersive X-ray Spectroscopy for elemental mapping, there is no such functionalit for EELS. That is why we implement the functionality in several steps: \n",
    "- Make a copy of the data to try several background removals\n",
    "- Remove the background of the full core-loss spectrum-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc355e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepcopy + remove_background\n",
    "cl_copy = core_loss...\n",
    "cl_copy..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7176715",
   "metadata": {},
   "source": [
    "- We then switch from Signal1D to Signal2D to enable easier interactive mapping. This would be the data equivalent of switch from a STEM-EELS spectrum-image acquisition to EFTEM spectrum-image acquisition.\n",
    "- We can then apply a `SpanROI` to select and map an energy range. The syntax is very similar to the custom data picker tool that we have seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_eftem = cl_copy.T\n",
    "roi = hs.roi.SpanROI()\n",
    "cl_eftem.plot()\n",
    "energy_span = roi.interactive(cl_eftem)\n",
    "elemental_map = hs.interactive(energy_span.mean)\n",
    "elemental_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175c66d",
   "metadata": {},
   "source": [
    "- To get nice maps, it is better to perform a background removal for each edge. Just below we can save the resulting map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "elemental_map..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5149a",
   "metadata": {},
   "source": [
    "#### üè† Converting `.hspy` data to Digital Micrograph (DM) readable format\n",
    "\n",
    "You first need to install this plugin in DM : [ripple plugin](http://hyperspy.org/hyperspy-doc/current/user_guide/io.html#importrpl-digital-micrograph-plugin)\n",
    "\n",
    "Then you just need to save your data in `.rpl` format using hyperspy. It will produce `.rpl` and `.raw` files. Using the DM plugin you'll be able to open the `.rpl` file and read your data in DM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elemental_map.save(\"NiL_845_to_854.rpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ed2a4",
   "metadata": {},
   "source": [
    "## Core-loss modelling\n",
    "\n",
    "Hyperspy has advanced model fitting features that:\n",
    "- use domain-specific knowledge and methods based on its signal child-type\n",
    "- use metadata as model parameters\n",
    "- gui elements for initilisation, etc ...\n",
    "\n",
    "You can save the model with the dataset.\n",
    "\n",
    "### Important arguments \n",
    "\n",
    "The `signal.create_model` function takes a few important arguments in EELS:\n",
    "- `GOS=` stands for Generalised Oscillator Strangth and we can use `\"dirac\"`, `\"dft\"`, `\"Hartree-Slater\"` or `\"hydrogenic\"`. The Hyperspy documentation recommends the use of `\"dft\"` for white lines and C, N and O edges. Relativistic effects are included using `\"dirac\"`.\n",
    "- `low_loss=` is the argument to include plural scattering correction\n",
    "\n",
    "More information on the `\"dft\"` and `\"dirac\"` related databases, see [dft DB](doi:10.5281/zenodo.7645765) and [dirac DB](doi:10.5281/zenodo.12800856).\n",
    "\n",
    "### Model options\n",
    "\n",
    "An exhaustive list of model functions is available in exspy or hyperspy documentation.\n",
    "\n",
    "- In most cases, it is important to enable the fine structure of core-loss edges for more accurate fitting. This is done using: `model.enable_fine_structure()`\n",
    "\n",
    "- In some cases, the valence of elements can change compared to the tabulated one. It will change the energy of the edge onset (this shift is usually called a chemical shift). You can use the function `model.enable_free_onset_energy()` to also fit the energy onset value. This feature can greatly help you if your energy scale is not fully accurate.\n",
    "\n",
    "- If you removed the background beforehand you should disable the background component with `model.disable_background()`\n",
    "\n",
    "### Single spectrum fitting\n",
    "\n",
    "While it is possible to fit STEM-EELS spectrum images, pixel by pixel, it is much faster to first test on a single spectrum. We are mostly interested in the average Ni/Fe ratio, that's why we cut the signal range to 50 eV before the Fe L3 edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "cl_mean = core_loss...\n",
    "# GOS and low-loss\n",
    "model = cl_mean.create_model(...)\n",
    "# enable fin structure\n",
    "model...\n",
    "# signal range\n",
    "model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b606e56",
   "metadata": {},
   "source": [
    "### Manually tuning initialisation\n",
    "\n",
    "Using the gui elements, it is possible to manually initialise the fitting parameters and add bounds to the parameters.\n",
    "\n",
    "I recommend using this interface only if the fit doesn't produce a valid result with the automatic initialisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "model...\n",
    "# gui\n",
    "model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9678ca5",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "\n",
    "The `smart_fit` method is tailored for EELS core-loss fitting for better modelling.\n",
    "\n",
    "The `fit` and `smart_fit` methods take two important arguments:\n",
    "- `loss_function=` is the method that measure the discrepancies between the data and the model. In general, people use the sum of the quadratic differences as a loss function called \"least square\" (it is the default value: `ls`). It is a mathematically correct formulation for data presenting a gaussian noise with fixed variance.\n",
    "  - Data with noise caracteristics with fixed variance is called \"homoscedastic\": \n",
    "  \n",
    "  ![image](images/Homoscedasticity.png)\n",
    "\n",
    "  - Data with noise caracteristics with variable variance (e.g. Poisson statistics) is called \"heteroscedastic\": \n",
    "  \n",
    "  ![image](images/Heteroscedasticity.png)\n",
    " \n",
    "   For most analysis the \"least square\" approach is good enough, however for a fully quantitative analysis it is better to use a tailored loss function.\n",
    "\n",
    "- `optimizer=` is the algorithm used to minimise the loss function, i.e. fit the model to the data (Most of the algorithms are well suited for optimizing the least square loss function). Hyperspy proposes two kinds of algorithms:\n",
    "  - \"local\" algorithm that can stop at a local minima of the loss function. \n",
    "  - \"global\" algorithm that can escape local minima by accepting temporarily parameter values that do not minimise the loss function. \n",
    "\n",
    "‚≠ê Hyperspy provides tools to estimate fitting errors on the parameters of the model, they can be accessed through the `std` value of fitted components.\n",
    "\n",
    "Fitting is a vast subject, please check the documention of Hyperspy or ask your QEM teacher for more information about fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smart fit\n",
    "model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e63436",
   "metadata": {},
   "source": [
    "### Plotting and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot + quantif\n",
    "model...\n",
    "model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a24f16",
   "metadata": {},
   "source": [
    "### Fitting spectrum images\n",
    "\n",
    "You can apply the fitting procedure to a whole spectrum image to obtain quantified elemental maps (for example). The process is a bit slow and thus we are only sharing the code and the results we obtained. Here is the code: \n",
    "\n",
    "```python\n",
    "# Load libraries\n",
    "%matplotlib qt\n",
    "import hyperspy.api as hs\n",
    "\n",
    "# Load data\n",
    "low_loss = hs.load('data/core_loss/EELS Spectrum Image (low-loss) (dark ref corrected).dm4')\n",
    "core_loss = hs.load('data/core_loss/EELS Spectrum Image (high-loss) (dark ref corrected).dm4')\n",
    "adf = hs.load(\"data/core_loss/Gatan BF_DF.dm4\")\n",
    "adf_survey = hs.load(\"data/core_loss/SI Survey Image.dm4\")\n",
    "\n",
    "# add metadata\n",
    "core_loss.add_elements(['Fe', 'Ni','O'])\n",
    "\n",
    "# Pre-process data\n",
    "low_loss.align_zero_loss_peak(also_align=[core_loss], signal_range=[-5.0,5.0])\n",
    "\n",
    "# Create the model\n",
    "model = core_loss.create_model(GOS = \"dirac\",low_loss = low_loss)\n",
    "model.enable_fine_structure()\n",
    "\n",
    "# Fit\n",
    "model.multifit(kind = \"smart\")\n",
    "\n",
    "# Plot the results\n",
    "model.plot_results()\n",
    "\n",
    "# Save the model\n",
    "model.save('Fe_Ni_O_model.hspy')\n",
    "```\n",
    "\n",
    "#### Fitted edge intensity\n",
    "\n",
    "\n",
    "![image](images/Figure_intensity_parameter_of_Fe_L3_component_Signal.png)\n",
    "![image](images/Figure_intensity_parameter_of_Ni_L3_component_Signal.png)\n",
    "![image](images/Figure_intensity_parameter_of_O_K_component_Signal.png)\n",
    "\n",
    "#### Elemental ratio maps\n",
    " \n",
    "![image](images/Fe_Ni_ratio.png)\n",
    "![image](images/Ni_ratio.png)\n",
    "![image](images/Fe_O_ratio.png)\n",
    "![image](images/O_Fe_ratio.png)\n",
    "\n",
    "‚ö†Ô∏è Oxygen quantification must be treated with care:\n",
    "- It is difficult to fit accurately.\n",
    "- It easily comes from extrinsic sources.\n",
    "- It is better estimated using charge balance (i.e. valence state study)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d3829",
   "metadata": {},
   "source": [
    "# IV. Low-loss analysis\n",
    "\n",
    "In this next part of the tutorial, we will focus on STEM-EELS low-loss data acquired on a Ag nano-triangle on Si3N4 substrate. Surface plasmon modes appear at the surface of the triangle under the excitation of the electron beam. These modes can be mapped using STEM-EELS, see for example : \"campos2017_plasmonic_mapping.pdf\". These modes represent a local enhancement of the electric field that can be used, for example, for catalysis.  \n",
    "\n",
    "This part of the notebook will help us answer the following questions:\n",
    "- What kind of spectral features is my sample exhibiting ?\n",
    "- What is the spatial distribution of these features ?\n",
    "- At what energy, the spectral features are the most intense ?\n",
    "\n",
    "The data pre-processing for low losses data shares some similarities with the above. Hence, we will go faster through the data loading and pre-processing, only emphasizing on the differences between low-loss and core-loss data analysis.\n",
    "\n",
    "The data were kindly provided by: **Hugo Louren√ßo-Martins**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c177593",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489182ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_spim = ...\n",
    "ll_adf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad96208",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da1ceb",
   "metadata": {},
   "source": [
    "### Energy alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy align\n",
    "ll_spim..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899264c",
   "metadata": {},
   "source": [
    "### Remove plural scattering\n",
    "\n",
    "The nanotriangle sits on a Si3N4 membrane that has also an intense plasmonic response. That is why we extract a spectrum from the substrate far away from the triangle to deconvolve the Si3N4 contribution from the interesting signal. \n",
    "\n",
    "#### Extracting Si3N4 contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c01165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ROI object. Without arguments it will use default coordinates, that are usually working well.\n",
    "roi = hs.roi.RectangularROI()\n",
    "\n",
    "# Plotting the different datasets\n",
    "ll_spim.plot()\n",
    "ll_adf.plot()\n",
    "\n",
    "# Linking the ROI with the datasets\n",
    "ll_select = roi.interactive(ll_spim)\n",
    "roi.interactive(ll_adf)\n",
    "\n",
    "# Summing over the spectrum images\n",
    "ll_spectrum = hs.interactive(ll_select.mean)\n",
    "\n",
    "# Plotting the spectra\n",
    "ll_spectrum.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa2b53",
   "metadata": {},
   "source": [
    "#### Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconvolution with area selection\n",
    "ll_spim..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f07fd",
   "metadata": {},
   "source": [
    "### Plasmonic mapping\n",
    "\n",
    "We can first manually extract plasmon maps by switching from `Signal1D` to `Signal2D`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_eftem = ll_spim.T\n",
    "roi = hs.roi.SpanROI()\n",
    "ll_eftem.plot()\n",
    "energy_span = roi.interactive(ll_eftem)\n",
    "plasmon_map = hs.interactive(energy_span.mean)\n",
    "plasmon_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cfb85b",
   "metadata": {},
   "source": [
    "#### Saving maps\n",
    "\n",
    "Don't forget to change the name each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasmon_map..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aed6ab",
   "metadata": {},
   "source": [
    "# V. Machine learning\n",
    "\n",
    "As stated above, the tools in the hands of the analyst are based on statistical priors on the data. It is even more important for machine learning tools such as Multivariate Statistical Analysis. Thus, in this section we will start by a non-exhaustive description of the statistics of EELS data.\n",
    "\n",
    "## EELS statistics\n",
    "\n",
    "The EELS processes are Poissonian in nature (see *EELS: EGERTON, Ray F. Electron energy-loss spectroscopy in the electron microscope. Springer Science & Business Media, 2011.*). Indeed, we observe a flow of electron over a given period of time and the inelastic scattering events are (in a good approximation) statistically independant from each other. It is often referred as shot noise.\n",
    "\n",
    "Then the detection system can add up different kinds of noise such as beam jittering or dark current. We will detail here only the detector related noises.\n",
    "\n",
    "### CCD detectors\n",
    "\n",
    "The variance of the statistical noise of the CCD is given by the following formula : \n",
    "\n",
    "$$ Var(J(E)) \\approx g + p J(E) $$\n",
    "\n",
    "Where $J(E)$ is the detected electron current, following a Poisson statistics. $p$ is a conversion proportionality constant and $g$ is an additive gaussian noise originating from read-out noise and dark current. The variance is not constant over the channels of the detector.\n",
    "\n",
    "### Direct detection\n",
    "\n",
    "The direct electron detectors are mostly limited by shot noise, thus the noise variance becomes : \n",
    "\n",
    "$$ Var(J(E)) \\approx p J(E) $$\n",
    "\n",
    "The absence of dark noise ($g$) drastically improve the performances of these detectors (especially at low doses). The variance is still not constant over the channels of the detectors.\n",
    "\n",
    "In general, the data acquired using direct detection are more straightforward to analyze.\n",
    "\n",
    "#### References\n",
    "\n",
    "*EGERTON, Ray F. Electron energy-loss spectroscopy in the electron microscope. Springer Science & Business Media, 2011.*\n",
    "\n",
    "*De la Pe√±a Manch√≥n, Francisco J. Advanced methods for Electron Energy Loss Spectroscopy core-loss analysis, PhD thesis, 2010*\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- **The methods presented here are very powerful but it may sometimes lead to wrong interpretations. If you plan to use them in your work we strongly recommend you to double check for the validity of the approach.** See for example: \"lichtert2013_PCA_artefacts.pdf\" in the references folder.\n",
    "\n",
    "- For more in depth information about direct electron detectors : see \"Hart2017_Direct_Detection_Electron_Energy-Loss_Spectroscopy.pdf\" in the references folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae47ec",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "Principal Component Analysis is a machine learning algorithm that can be used for data analysis or for denoising of multidimensional data. It is based on statistical principles and it is used in a wide variety of domains from text analysis to meteorology and STEM-EELS is no exception.\n",
    "\n",
    "### Principle\n",
    "\n",
    "The data below are represented using two main axes, x and y. Each of those axes correspond to some variance of the data as it can be seen in the projection of the data on those axes (thick redlines). \n",
    "\n",
    "![image](images/random_data.png)\n",
    "\n",
    "The PCA will reorganise the axes on which the data are represented. The axes are rotated so that they correspond to gradually decreasing variance of the data. It means that the first axis (arrow parallel the line) is represents the highest variance in the data (Thick blue line) and the second axis (arrow perpendicular to the line) represents lower variance (thick green line). \n",
    "\n",
    "![image](images/random_data_PCA.png)\n",
    "\n",
    "For the data analysis, this reorganisation of the axes is useful. With the new representation we easily get that the main feature of the signal is the straight line and that the axis perpendicular to it represents mainly noise. **In general, after PCA you should determine which are the relevant axes (or components) describing your signal and discard the noisy ones.**\n",
    "\n",
    "### The impact of noise statistics\n",
    "\n",
    "In contrast to the data presented just above, the STEM-EELS data are heteroscedastic. The reorganisation of the axes will not occur in the same way. Therefore, a correction of this effect is required. That is also why it is important to understand the statistics of the data you analyze.\n",
    "\n",
    "![image](images/poisson_data.png)\n",
    "\n",
    "### Increasing the dimension of the data\n",
    "\n",
    "The PCA principles apply even with data of higher dimension. For spectrum images, they can be represented as a collection of spectra (N pixels spectra). A point in 2D space corresponds to 2 coordinates (x,y). A point in 3D space corresponds to 3 coordinates (x,y,z). A spectrum can be seen as a point in E-dimensional space ($I_1, I_2, ..., I_E$).\n",
    "\n",
    "![image](images/flat_spim.png)\n",
    "\n",
    "PCA is going to decompose the data in two matrices. The first matricx called factors contains the vectors of the new representation, each column contains one spectrum-like axis. Each row of the second matrix (called loadings) correspond to the intensity of a given axis of the new representation. In the previous part with the line, the first line of the loadings will give out where each point is on the line. \n",
    "\n",
    "![image](images/decomposition.png)\n",
    "\n",
    "For example, a spectral signature with high variance (such as the zero-loss peak) will have it's own axis in the new representation. Thus, there will be a corresponding loading describing the spatial evolution of the zero-loss peak intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995e606",
   "metadata": {},
   "source": [
    "### Applying PCA\n",
    "\n",
    "We use the `spim.decomposition` function to perform the PCA. Using the positional argument `spim.decomposition(True)`, the poissonian nature of the noise is taken into account (within some approximation). \n",
    "\n",
    "‚≠ê For fully taking into account the poisson statistics, you will need to use the maximum likelihood formulation of the algorihtm. This is more computationnally expensive though.\n",
    "\n",
    "### References \n",
    "\n",
    "see \"keenan2004_PCA_Poisson_normalisation.pdf\" in the references folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomp + poisson\n",
    "ll_spim..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd6b94",
   "metadata": {},
   "source": [
    "### Explained variance ratio\n",
    "\n",
    "To help you determine the relevant components in your dataset, there is a tool in hyperspy to plot how much variance of the data correspond to each axis of the new representation. \n",
    "\n",
    "This plot organises the axes by decreasing variance. Often, this plot as an elbow shape. As a rule of thumb, the number of relevant components is approximately given by the position of the elbow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27aae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot explained ratio\n",
    "ll_spim..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4b8de",
   "metadata": {},
   "source": [
    "### Plotting the results\n",
    "\n",
    "Hyperspy provides gui elements to plot the decomposition results. You can browse interactively through the loadings and factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot decomp results\n",
    "ll_spim..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd4ab6",
   "metadata": {},
   "source": [
    "You can also plot independantly the factors and the loadings using `spim.plot_decomposition_factors` and `spim.plot_decomposition_loadings`. Here are a few useful options for display: \n",
    "\n",
    "- You can use an integer `spim.plot_decomposition_factors(3)`, which will display the 3 first factors. Or you can use a list `spim.plot_decomposition_factors([1,3,5])` which will display the factors 1, 3 and 5 only.\n",
    "\n",
    "- You can plot everything in separated windows using the `same_window = False` keyword argument\n",
    "\n",
    "üè† The syntax is really similar if you want to put the factors or loadings in a separate hyperspy signal with `spim.get_decomposition_factors` and `spim.get_decomposition_loadings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa378e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_spim.plot_decomposition_factors(3,same_window = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1700027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_spim.plot_decomposition_loadings(3,same_window = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba789e",
   "metadata": {},
   "source": [
    "## NMF\n",
    "\n",
    "### Principles\n",
    "\n",
    "The Non-Negative Matrix Factorization is somewhat similar to PCA. It decomposes the data into factors and loadings, although they are not organized according to decreasing variance. The main difference is that the factors and loadings are constrained to positive values. \n",
    "\n",
    "We activate the NMF using the keyword argument `algorithm = 'NMF'`. It is an iterative algorithm and the calculation is much longer. That is why, We limit beforehand the number of components using the keyword argument `output_dimension = n`, where `n` is the integer you choose. The algorithm might not converge with the default amount of iterations, you can use `max_iter=` to increase it.\n",
    "\n",
    "**The PCA modifies the spim object. It is recommended to reload the data before performing NMF.**\n",
    "\n",
    "‚≠ê Hyperspy has a flexible enough interface. You can use many different decomposition algorithms such as the ones of scikit-learn with more or less the same syntax. For example, the value of `algorithm=` can be any object that implements the `fit` and `transform` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b967d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson + NMF + out dim + max iter\n",
    "ll_spim.decomposition(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4065c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "ll_spim..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfafca",
   "metadata": {},
   "source": [
    "## Understanding the results\n",
    "\n",
    "The plasmon modes in nanotriangles can be divide in edge modes and pseudo-radial breathing modes (RBMs). RBMs have typically higher energy than edge modes. You can compare your extracted maps to the litterature.\n",
    "\n",
    "![image](images/campos2017_maps.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
